# -*- coding: utf-8 -*-
"""Facial_emotion_detection_spotle.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bBzwQ1uBk89NEhjBxfw5yhfUu9FxrMzJ
"""

#from google.colab import drive
#drive.mount('/content/drive')

#pip freeze > requirements.txt

"""### Importing Libraries"""

import glob
import cv2
import re
import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt
#import tqdm as tqdm
#from tqdm.notebook import tqdm

from tensorflow import keras

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg19 import VGG19
# from tensorflow.keras.applications.inception_v3 import InceptionV3 
from tensorflow.keras.models import load_model
from tensorflow.keras import utils
#from keras.utils.np_utils import to_categorical 
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import DirectoryIterator
#from tensorflow.keras.applications.resnet import preprocess_input

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# from tensorflow.keras.applications.resnet import ResNet101
# from tensorflow.keras.applications.resnet_v2 import ResNet101V2
# from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2

from sklearn.model_selection import train_test_split

"""### Read data"""

data = pd.read_csv("data/aithon2020_level2_traning.csv")


"""### Read the data as grayscale images"""

X = []
y_cat= []
for tup in data.itertuples():
      image = np.array(tup[2:]).reshape(48,48).astype(float).tolist()
      X.append(image)
      y_cat.append(tup[1])
X = np.array(X)#.reshape(-1,48,48,1)

### One hot encoding of Label
# print("Unique labels:",set(y_cat))
# convert_array = {'Happy': [1,0,0],'Sad': [0,1,0],'Fear':[0,0,1] }
# # X = np.array(X).reshape(-1,48,48,1)
# #y_encoded = np.array([convert_array[i] for i in y_cat])
# #y = np.eye(len(set(y_encoded)))[y_encoded]
# y = np.array([convert_array[i] for i in y_cat])
# y.shape

"""### Check no of data points corresponding to each class"""

dic = {}
for key in y_cat:
  try:
    dic[key] += 1
  except:  
    dic[key] = 1

for key in dic.keys():
  print("No of images for category {} : {} ".format(key, dic[key]))

"""### Convert Gray scale to RGB (by repeating the same channel)"""

X_rgb = []
for item in X:
      X_rgb.append(np.stack((item,)*3,axis = -1).tolist())
X_rgb = np.array(X_rgb)

"""### Resize the RGB image (as required for the pre-trained model)"""

width = 80
height = 80
dim = (width, height)
 
temp  = X_rgb
X = []
for i in range(len(temp)):
  X.append(cv2.resize(temp[i],dim))
X = np.array(X)

"""### Train-Test split"""

X_train, X_test, y_train, y_test = train_test_split( X, y_cat, test_size=0.30, random_state=42, shuffle=True)

"""### Oversampling for training data"""

train_dic = {}
for i in range(len(y_train)):
  try:
    train_dic[y_train[i]].append(X_train[i])
  except:  
    train_dic[y_train[i]] = [X_train[i]]

for key in train_dic.keys():
  print("No of images for category {} in training data: {} ".format(key, len(train_dic[key])))

m = max([len(train_dic[key]) for key in train_dic.keys()])
for key in train_dic.keys():
     l =(m - len(train_dic[key]))
     if l!= 0:
      #print(np.array(random.choices(dic[key],k=l)).shape)
      X_train = np.concatenate((X_train, np.array(random.choices(train_dic[key],k=l))))
      y_train = np.concatenate((y_train,np.array([key]*l)),axis=0)
      #y = np.concatenate((y,np.stack((np.array(convert_array[key]),)*l)),axis=0)

print(X_train.shape)
print(y_train.shape)

"""### One hot encoding of label"""

print("Unique labels:",set(y_cat))
convert_array = {'Happy': [1,0,0],'Sad': [0,1,0],'Fear':[0,0,1] }
# X = np.array(X).reshape(-1,48,48,1)
#y_encoded = np.array([convert_array[i] for i in y_cat])
#y = np.eye(len(set(y_encoded)))[y_encoded]
y_train = np.array([convert_array[i] for i in y_train])
y_test = np.array([convert_array[i] for i in y_test])

print("No of training data:",X_train.shape[0])
print("No of validation data:",X_test.shape[0])

"""### Define Model"""

IMAGE_SIZE = 80

base_model = VGG16(include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights="imagenet") 
 
base_model.trainable = True


model = Sequential([base_model])
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(256, activation = "relu"))
#model.add(BatchNormalization())
model.add(Dropout(0.25))
# model.add(Dense(128, activation = "relu"))
# model.add(Dropout(0.5))
model.add(Dense(3, activation = "softmax"))

optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)
#optimizer = RMSprop(learning_rate=0.001)


model.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])

def fit_model(model,epochs = 50, batch_size = 64, data_augmentation = False):

    rlr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience= 3, verbose=1, mode='auto', min_lr=0)

    if not data_augmentation:
      print("Fitting model without using Data Augmenatation.")
      history = model.fit(X_train, y_train,
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(X_test, y_test),
              shuffle=True, verbose = 2, callbacks=[rlr])
    else:
      print("Fitting model using Data Augmenatation.")
      datagen = ImageDataGenerator(
        featurewise_center=True,  # set input mean to 0 over the dataset
        samplewise_center=True,  # set each sample mean to 0
        featurewise_std_normalization=True,  # divide inputs by std of the dataset
        samplewise_std_normalization=True,  # divide each input by its std
        zca_whitening=True,  # apply ZCA whitening
        zca_epsilon=1e-06,  # epsilon for ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        # randomly shift images horizontally (fraction of total width)
        width_shift_range=0.,
        # randomly shift images vertically (fraction of total height)
        height_shift_range=0.,
        shear_range=0.,  # set range for random shear
        zoom_range=0.1,  # set range for random zoom
        channel_shift_range=0.,  # set range for random channel shifts
        # set mode for filling points outside the input boundaries
        fill_mode='nearest',
        cval=0.,  # value used for fill_mode = "constant"
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        # set rescaling factor (applied befor/e any other transformation)
        rescale=None)
      
      datagen.fit(X_train)
      history = model.fit_generator(datagen.flow(X_train, y_train,
                                     batch_size=batch_size),
                        epochs=epochs,
                        validation_data=(X_test, y_test),
                        shuffle = True,verbose = 2, callbacks=[rlr])
    return history

"""### Fit the model"""

history = fit_model(model, data_augmentation=False)

"""### For prediction"""

model.predict()



